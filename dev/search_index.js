var documenterSearchIndex = {"docs":
[{"location":"quick/#Quick-Interface","page":"Quick Interface","title":"Quick Interface","text":"","category":"section"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"The Quick Interface is designed for defining simple POMDPs in a few lines without any object oriented programming. It exposes nearly all of the problem definition features of POMDPs.jl through constructor keyword arguments.","category":"page"},{"location":"quick/#Example","page":"Quick Interface","title":"Example","text":"","category":"section"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"The quick interface is perhaps best demonstrated by an example. The code below defines the classic \"Mountain Car\" problem from  OpenAI Gym.","category":"page"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"using QuickPOMDPs\nusing POMDPTools: Deterministic\n\nmountaincar = QuickMDP(\n    function (s, a, rng)        \n        x, v = s\n        vp = clamp(v + a*0.001 + cos(3*x)*-0.0025, -0.07, 0.07)\n        xp = x + vp\n        if xp > 0.5\n            r = 100.0\n        else\n            r = -1.0\n        end\n        return (sp=(xp, vp), r=r)\n    end,\n    actions = [-1., 0., 1.],\n    initialstate = Deterministic((-0.5, 0.0)),\n    discount = 0.95,\n    isterminal = s -> s[1] > 0.5\n)","category":"page"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"Here, the first argument to the QuickMDP constructor is a function that defines the generative model of the MDP. It returns a NamedTuple containing the next state and reward given the current state and action.","category":"page"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"note: Note\nQuick(PO)MDPs need not be generative models. Explicit Quick(PO)MDPs can be defined by leaving out the generative function positional argument and providing the transition, observation, and reward keyword arguments. An example of this style can be found in examples/lightdark.jl.","category":"page"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"The other keyword arguments define the remaining elements of the problem such as the action space, discount factor and when to terminate.","category":"page"},{"location":"quick/#Keyword-arguments","page":"Quick Interface","title":"Keyword arguments","text":"","category":"section"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"The keyword arguments correspond to functions in the POMDPs.jl interface. More information for each can be found in the docstring for the function.","category":"page"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"The currently supported keyword arguments are","category":"page"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"transition\nobservation\ninitialstate_distribution\nreward\ninitialstate\ninitialobs\nstates\nactions\nobservations\ndiscount\nstateindex\nactionindex\nobsindex\nisterminal\nobs_weight (from POMDPModelTools)\nrender (from POMDPModelTools)","category":"page"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"note: Note\nThe gen function (which should always return a NamedTuple) can be defined as a first positional argument (or with the do syntax) or using the gen keyword.","category":"page"},{"location":"quick/#Keyword-arguments-may-be-functions-or-objects","page":"Quick Interface","title":"Keyword arguments may be functions or objects","text":"","category":"section"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"Most keyword arguments may be either functions or static objects. For instance, in the above example, the action space is specified by a static list provided as the actions keyword argument. In other problems, the action space might be state-dependent and hence specified as a function of the state, for instance if the mountain car only had a braking action, the following code might be used:","category":"page"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"actions = function (s) \n    v = s[2]\n    if v >= 0.0\n        return [0., -1.]\n    else\n        return [0., 1.]\n    end\nend","category":"page"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"When the keyword argument is a function, it should take all of the arguments that the corresponding POMDPs.jl function takes, but without the model argument. For instance, the signature for POMDPs.isterminal is isterminal(m::Union{POMDP, MDP}, s), so the isterminal keyword argument takes a function of only s (the m model argument is omitted) as shown in the example above.","category":"page"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"note: Note\nFor the actions case above, you may want to also provide the full action space, that is, you may want to allow someone to call actions(m), but the method above only provides actions(m, s) to the solver or simulator. This can be remedied by adding a default for the s argumentactions = function (s=nothing)\n    if isnothing(s)\n        return [-1., 0., 1.]\n    end\n    # handle cases where s is supplied as above.\nend","category":"page"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"note: Note\nWhen the POMDPs.jl function has a variable number of arguments, it can be confusing to know which version to implement. For example POMDPs.jl has the methodsreward(m, s, a)\nreward(m, s, a, sp)\nreward(m, s, a, sp, o)in the interface. Usually the best bet is to implement the one with the most arguments, i.e.reward = (s, a, sp, o) -> s^2However, in general, a specific solver may require a specific number of arguments (keep an eye out for MethodErrors to know which version is needed). If multiple methods are needed, they can be defined outside of the Quick(PO)MDP constructor, e.g.myreward(s, a) = s^2\nmyreward(s, a, sp) = s^2\nm = QuickMDP(\n    ...\n    reward = myreward,\n    ...\n)","category":"page"},{"location":"quick/#IDs-and-defining-methods","page":"Quick Interface","title":"IDs and defining methods","text":"","category":"section"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"Each Quick(PO)MDP has a unique id, which is stored as a type parameter. By default this id is randomly generated, but it can also be specified as a positional argument.","category":"page"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"This ID type parameter allows specialized methods to be defined for a specific Quick(PO)MDP. For example one could override ordered_states function from POMDPModelTools as follows:","category":"page"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"m = QuickMDP(...)\n\nPOMDPModelTools.ordered_states(m::typeof(m)) = 1:3","category":"page"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"or","category":"page"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"m = QuickMDP(:myproblem, ...)\n\nPOMDPModelTools.ordered_states(m::QuickMDP{:myproblem}) = 1:3","category":"page"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"note: Note\nA manually-specified ID must be a suitable type parameter value such as a Symbol or other isbits type.","category":"page"},{"location":"quick/#State,-action,-and-observation-type-inference","page":"Quick Interface","title":"State, action, and observation type inference","text":"","category":"section"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"The state, action, and observation types for a Quick(PO)MDP are usually inferred from the keyword arguments. For instance, in the example above, the state type is inferred to be Tuple{Float64, Float64} from the initialstate argument, and the action type is inferred to be Float64 from the actions argument. If QuickPOMDPs is unable to infer one of these types, or the user wants to override or specify the type manually, the statetype, actiontype, or obstype keywords should be used.","category":"page"},{"location":"quick/#Visualization","page":"Quick Interface","title":"Visualization","text":"","category":"section"},{"location":"quick/","page":"Quick Interface","title":"Quick Interface","text":"Visualization can be accomplished using the render keyword argument. See the documentation of POMDPModelTools.render for more information. An example can be found in example/mountaincarwithvisualization.jl.","category":"page"},{"location":"discrete_explicit/#Discrete-Explicit-Interface","page":"Discrete Explicit Interface","title":"Discrete Explicit Interface","text":"","category":"section"},{"location":"discrete_explicit/","page":"Discrete Explicit Interface","title":"Discrete Explicit Interface","text":"The Discrete Explicit Interface is designed to match the standard definition of a POMDP in the literature as closely as possible. The standard definition uses the tuple (S,A,O,T,Z,R,γ) for a POMDP and (S,A,T,R,γ) for an MDP, where","category":"page"},{"location":"discrete_explicit/","page":"Discrete Explicit Interface","title":"Discrete Explicit Interface","text":"S, A, and O are the state, action, and observation spaces,\nT and Z are the transition and observation probability distribution functions (pdfs),\nR is the reward function, and\nγ is the discount factor.","category":"page"},{"location":"discrete_explicit/","page":"Discrete Explicit Interface","title":"Discrete Explicit Interface","text":"The DiscreteExplicitPOMDP and DiscreteExplicitMDP types are provided for POMDPs and MDPs with discrete spaces and explicitly defined distributions. They should offer moderately good performance on small to medium-sized problems. Instructions for defining the initial distribution and terminal states can be found in the docstrings.","category":"page"},{"location":"discrete_explicit/#Example","page":"Discrete Explicit Interface","title":"Example","text":"","category":"section"},{"location":"discrete_explicit/","page":"Discrete Explicit Interface","title":"Discrete Explicit Interface","text":"The classic tiger POMDP [Kaelbling et al. 98] can be defined as follows:","category":"page"},{"location":"discrete_explicit/","page":"Discrete Explicit Interface","title":"Discrete Explicit Interface","text":"using QuickPOMDPs\n\nS = [:left, :right]           # S, A, and O may contain any objects\nA = [:left, :right, :listen]  # including user-defined types\nO = [:left, :right]\nγ = 0.95\n\nfunction T(s, a, sp)\n    if a == :listen\n        return s == sp\n    else # a door is opened\n        return 0.5 #reset\n    end\nend\n\nfunction Z(a, sp, o)\n    if a == :listen\n        if o == sp\n            return 0.85\n        else\n            return 0.15\n        end\n    else\n        return 0.5\n    end\nend\n\nfunction R(s, a)\n    if a == :listen  \n        return -1.0\n    elseif s == a # the tiger was found\n        return -100.0\n    else # the tiger was escaped\n        return 10.0\n    end\nend\n\nm = DiscreteExplicitPOMDP(S,A,O,T,Z,R,γ)","category":"page"},{"location":"discrete_explicit/#Constructor-Documentation","page":"Discrete Explicit Interface","title":"Constructor Documentation","text":"","category":"section"},{"location":"discrete_explicit/","page":"Discrete Explicit Interface","title":"Discrete Explicit Interface","text":"DiscreteExplicitMDP\nDiscreteExplicitPOMDP","category":"page"},{"location":"discrete_explicit/#QuickPOMDPs.DiscreteExplicitMDP","page":"Discrete Explicit Interface","title":"QuickPOMDPs.DiscreteExplicitMDP","text":"DiscreteExplicitMDP(S,A,T,R,γ,[p₀],[terminals=Set()])\n\nCreate an MDP defined by the tuple (S,A,T,R,γ).\n\nArguments\n\nRequired\n\nS,A: State and action spaces (typically Vectors)\nT::Function: Transition probability distribution function; T(sas) is the probability of transitioning to state s from state s after taking action a.\nR::Function: Reward function; R(sa) is the reward for taking action a in state s.\nγ::Float64: Discount factor.\n\nOptional\n\np₀=Uniform(S): Initial state distribution (See POMDPModelTools.Deterministic and POMDPModelTools.SparseCat for other options).\n\nKeyword\n\nterminals=Set(): Set of terminal states. Once a terminal state is reached, no more actions can be taken or reward received.\n\n\n\n\n\n","category":"type"},{"location":"discrete_explicit/#QuickPOMDPs.DiscreteExplicitPOMDP","page":"Discrete Explicit Interface","title":"QuickPOMDPs.DiscreteExplicitPOMDP","text":"DiscreteExplicitPOMDP(S,A,O,T,Z,R,γ,[b₀],[terminals=Set()])\n\nCreate a POMDP defined by the tuple (S,A,O,T,Z,R,γ).\n\nArguments\n\nRequired\n\nS,A,O: State, action, and observation spaces (typically Vectors)\nT::Function: Transition probability distribution function; T(sas) is the probability of transitioning to state s from state s after taking action a.\nZ::Function: Observation probability distribution function; O(a s o) is the probability of receiving observation o when state s is reached after action a.\nR::Function: Reward function; R(sa) is the reward for taking action a in state s.\nγ::Float64: Discount factor.\n\nOptional\n\nb₀=Uniform(S): Initial belief/state distribution (See POMDPModelTools.Deterministic and POMDPModelTools.SparseCat for other options).\n\nKeyword\n\nterminals=Set(): Set of terminal states. Once a terminal state is reached, no more actions can be taken or reward received.\n\n\n\n\n\n","category":"type"},{"location":"discrete_explicit/#Usage-from-Python","page":"Discrete Explicit Interface","title":"Usage from Python","text":"","category":"section"},{"location":"discrete_explicit/","page":"Discrete Explicit Interface","title":"Discrete Explicit Interface","text":"The Discrete Explicit interface can be used from python via pyjulia. See examples/tiger.py for an example.","category":"page"},{"location":"#QuickPOMDPs.jl","page":"QuickPOMDPs.jl","title":"QuickPOMDPs.jl","text":"","category":"section"},{"location":"","page":"QuickPOMDPs.jl","title":"QuickPOMDPs.jl","text":"QuickPOMDPs is a package that makes defining Markov decision processes (MDPs) and partially observable Markov decision processes easy.","category":"page"},{"location":"","page":"QuickPOMDPs.jl","title":"QuickPOMDPs.jl","text":"The models defined with QuickPOMDPs are compatible with POMDPs.jl and can be used with any solvers from that ecosystem that are appropriate for the problem.","category":"page"},{"location":"","page":"QuickPOMDPs.jl","title":"QuickPOMDPs.jl","text":"Defining a model with QuickPOMDPs does not require any object-oriented programming, so this package may be easier for some users (e.g. those coming from MATLAB) to pick up than POMDPs.jl itself.","category":"page"},{"location":"","page":"QuickPOMDPs.jl","title":"QuickPOMDPs.jl","text":"QuickPOMDPs contains two interfaces:","category":"page"},{"location":"","page":"QuickPOMDPs.jl","title":"QuickPOMDPs.jl","text":"The Discrete Explicit Interface, is suitable for problems with small discrete state, action, and observation spaces. This interface is pedagogically useful because each element of the (S A O R T Z gamma) tuple for a POMDP and (S A R T gamma) tuple for an MDP is defined explicitly in a straightforward manner. See the Discrete Explicit Interface page for more details.\nThe Quick Interface is much more flexible, exposing nearly all of the features of POMDPs.jl as constructor keyword arguments. See the Quick Interface page for more details.","category":"page"},{"location":"","page":"QuickPOMDPs.jl","title":"QuickPOMDPs.jl","text":"See the Solver tutorials in the POMDPExamples package for examples of how to solve and simulate problems defined with QuickPOMDPs.","category":"page"},{"location":"","page":"QuickPOMDPs.jl","title":"QuickPOMDPs.jl","text":"Contents","category":"page"},{"location":"","page":"QuickPOMDPs.jl","title":"QuickPOMDPs.jl","text":"Pages = [\"discrete_explicit.md\", \"quick.md\"]","category":"page"}]
}
